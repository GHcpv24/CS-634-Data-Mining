{"cells":[{"cell_type":"markdown","metadata":{"id":"7H_KJxkZqT6j"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1AeVWJn0TWtr4DjV99uZ3ONGRWF0W-FIR?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"wiQzeJbKqTwb"},"source":["Submitted By: Chiara Vega"]},{"cell_type":"markdown","metadata":{"id":"PZrYhGKIqN-3"},"source":["# Problem Set 1 - Take at home (50 Points)\n","\n","## PS1.A (15 points)\n","\n","\n","![](images/autoencoder.png)\n","\n","Design a neural system that will receive an input image from the CIFAR10 dataset and it will _reconstruct it_ at the output.\n","\n","To do so the encoder must compress the input image into a vector of size $d$ and the decoder must reconstruct the image from the vector of size $d$.\n","\n","The encoder spatial dimensions of its output feature maps will determined by the input height or width (i), kernel (k), padding (p), and stride (s), producing the output feature map (o) size that is given by\n","\n","$$o = \\frac{i-k+2p}{s}+1$$\n","\n","The decoder must make use of a number of _transposed convolutional_ layers - each successively upsamples its input feature map. The operation is the inverse of the earlier question on representing convolution as a matrix by vector product:\n","\n","$$x = C^T y$$\n","\n","For a given size of the input (i), kernel (k), padding (p), and stride (s), the size of the output feature map (o) generated is given by\n","\n","$$o = s(i-1)+k-2p$$\n","\n","Ultimately the size of the input image is produced at the output of the decoder and this would allow the comparison of the original input image and the decoded image $\\tilde x$.  \n","\n","Your design should include all dimensions of the encoder and decoder CNNs including the number of layers, number of filters and spatial dimensions, the activation functions, the loss function, the optimizer. You need to expose this information via the API (you can use any framework you know).\n","\n"]},{"cell_type":"code","source":["# type here the python model of the autoencoder\n","\n","# please note that elements of the model that are typed in without any explanation will receive 0 points"],"metadata":{"id":"bytd3hNFq3w9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this section, an autoencoder model CNN model is specifically designed for image reconstruction using the CIFAR10 dataset. The PyTorch `nn.Module` is used to implement the autoencoder CNN model as a class called `Autoencoder`. The **encoder** and the **decoder** are the two fundamental parts of the autoencoder architecture.\n","\n","**Encoder**\n","\n","The encoder's function is to compress the input image into a lower-dimensional representation. Multiple convolutional layers are used in the construction of the encoder, each of which is, of course, followed by ReLU activation functions. as well as max-pooling layers. These convolutional and pooling layers are implemented using 'nn.Conv2d' and 'nn.MaxPool2d'. The first convolutional layer applies 64 3x3 filters, with padding of 1 and stride of 1, to input images with 3 channels (representing RGB color). Non-linearity is introduced through ReLU activation, facilitating feature extraction. The spatial dimensions of the feature map are reduced using a subsequent max-pooling layer with a kernel size of 2x2 and a stride of 2. The same pattern is followed by additional convolutional layers, each with 128 filters. The encoder yields an 8x8x128-pixel compressed feature map as its output.\n","\n","**Decoder**\n","\n","The decoder attempts to reconstruct the original image from this compressed form. Transposed convolutional layers (`nn.ConvTranspose2d`), ReLU activation functions, and a final sigmoid activation are used to implement the decoder. Upsampling the compressed feature map to the original image size is the decoder's main objective. The compressed feature map is accepted by the first transposed convolutional layer, which then applies 64 filters of size 4x4 with padding of 1 and stride of 2. ReLU activation increases the reconstruction process by introducing non-linearity. The subsequent second transposed convolutional layer then applies 3 filters of size of 4x4 and padding of 1 and stride of 2 . The [0, 1] range, which represents the pixel values of the reconstructed image, is restricted for the output of the decoder by the final sigmoid activation.\n","\n","**Linear Layer**\n","\n","A linear layer (`nn.Linear`) is added to the encoder's output feature map in order to further compress it, creating a vector with a size of 128 - for the input data to be represented more effectively.\n","\n","**Loss Function and Optimizer**\n","\n","The Mean Squared Error (MSE) loss function is used in training the autoencoder - the objective being to measure and minimize the discrepancies between the original images and the reconstructed images. Due to being well-noted to be a highly popular optimization technique, this model will use the Adam optimizer, along with a learning rate of 0.001 and weight decay of 0.001."],"metadata":{"id":"8EhOlskwVhfS"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePDzixMUqx7b","executionInfo":{"status":"ok","timestamp":1691053958005,"user_tz":240,"elapsed":5022,"user":{"displayName":"C Vega","userId":"16458062472798774276"}},"outputId":"74398d45-33bc-4034-ed6b-40da04eaf48f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n","  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.19)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.10.0 colorlog-6.7.0 optuna-3.2.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqYg9N2E8Bka"},"outputs":[],"source":["# Import necessary libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import optuna"]},{"cell_type":"code","source":["# Can use for reproducibility\n","#torch.manual_seed(0)"],"metadata":{"id":"ksRMKGMrvOBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_Pzm_ti8Jff"},"outputs":[],"source":["# Define the Autoencoder class\n","class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder, self).__init__()\n","\n","        # Encoder layers\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # o = (i - k + 2p) / s + 1\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # o = (i - k + 2p) / s + 1\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # o = (i - k + 2p) / s + 1\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # o = (i - k + 2p) / s + 1\n","        )\n","\n","        # Decoder layers\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # o = s(i-1) + k - 2p\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # o = s(i-1) + k - 2p\n","            nn.Sigmoid(),\n","        )\n","\n","        # Linear layer to compress the input into a vector of size 128\n","        self.linear = nn.Linear(8 * 8 * 128, 128)\n","\n","    def forward(self,x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","# Loss function and optimizer\n","model = Autoencoder()\n","criterion = nn.MSELoss()  # Mean Squared Error loss for reconstruction\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)"]},{"cell_type":"markdown","metadata":{"id":"nm-KxmplIMY1"},"source":["# PS1.B (15 points)\n","\n","Train your PS1.A autoencoder  and produce the validation or test loss as a number of epochs. Make sure you explain any preprocessing stages and ensure you show the hyperparameter tuning process in your code.\n","\n"]},{"cell_type":"code","source":["# Type here the training code for the autoencoder and the code for the prediction of the test set\n","\n","# please note that elements of the training code that are typed in without any explanation will receive 0 points"],"metadata":{"id":"EumlNOUqrkEj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["With the autoencoder CNN model designed, the subsequent step will be to train the model on the CIFAR10 dataset.\n","\n","**Data Preprocessing**\n","\n","Data Preprocessing is an important step that must be accomplished prior to training - beginning with `transforms.Compose` function from Pytorch to define a series of transformations. The transformed images were turned into tensors (`ToTensor`) and the pixel values normalized (`Normalize`) to lie within the range [-1, 1].\n","\n","**DataLoader**\n","\n","After data preprocessing, the CIFAR10 datasets loaded from `datasets.CIFAR10` and organized into `DataLoader` for efficient facilitation of batches for training and testing, along with being set to shuffle.\n","\n","**Hyperparameter Tuning**\n","\n","Optuna will be used for hyperparameter tuning. Firstly, a function called `validation_loss` is defined to calculate the validation loss - where the model is put into evaluation by `model.eval()` and the test DataLoader is iterated over in order to calculate the validation loss. Similarly stated in the previous section, MSE loss function will be used. Optuna study's `objective` function will determine the best combination of hyperparameters for the model, specifically the learning rate (`lr`) and weight decay (`weight_decay`). The training loop is repeated by the function for a 5 epochs. The model is trained using the Adam optimizer with the predetermined learning rate and weight decay throughout each epoch. At the conclusion of each period, the validation loss is calculated and printed. The optimal hyperparameters are obtained via `study.best_params` following the hyperparameter tuning - where the training loop is repeated with the best learning rate and weight decay. The Adam optimizer is used to train the final model using the optimal hyperparameters. And each epoch's training loss is printed during the final training.\n","\n","**Test Loss Calculation**\n","\n","In order to calculate the test loss, the trained model is assessed on the test set, with the MSE loss function used to compute the average test loss after iterating the test DataLoader.\n","\n","You will find that the test loss (MSE) is: 0.1437."],"metadata":{"id":"Kpdy6P-PZW8F"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18378,"status":"ok","timestamp":1691053979550,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"E0f4v4_cIu5k","outputId":"b484af76-8b51-41d5-a48a-c218e70a9d11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:12<00:00, 13724443.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# Data Preprocessing\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1]\n","])\n","\n","train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwvpVdMEI9in"},"outputs":[],"source":["# Function to calculate the validation loss\n","def validation_loss(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss = 0.0\n","    with torch.no_grad():\n","        for inputs, _ in dataloader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, inputs)\n","            total_loss += loss.item() * inputs.size(0)\n","    model.train()\n","    return total_loss / len(dataloader.dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409253,"status":"ok","timestamp":1691054388796,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"tQhg2Xf1IL_Y","outputId":"cad662e5-50a5-4111-bd8c-4720d1761553"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2023-08-03 09:12:53,486] A new study created in memory with name: no-name-7d4e3995-7f78-479c-b232-de08bab72b9f\n","[I 2023-08-03 09:14:26,138] Trial 0 finished with value: 0.14526146059036255 and parameters: {'lr': 0.0006176026261782298, 'weight_decay': 0.00017266991418482335}. Best is trial 0 with value: 0.14526146059036255.\n","[I 2023-08-03 09:15:44,172] Trial 1 finished with value: 0.14318454551696777 and parameters: {'lr': 0.0002879948240762162, 'weight_decay': 5.7906721789705734e-05}. Best is trial 1 with value: 0.14318454551696777.\n","[I 2023-08-03 09:17:02,254] Trial 2 finished with value: 0.15730477073192597 and parameters: {'lr': 1.0990048244125832e-05, 'weight_decay': 9.811819704589201e-05}. Best is trial 1 with value: 0.14318454551696777.\n","[I 2023-08-03 09:18:22,306] Trial 3 finished with value: 0.14876255395412444 and parameters: {'lr': 3.094919955898236e-05, 'weight_decay': 3.56125386439924e-05}. Best is trial 1 with value: 0.14318454551696777.\n","[I 2023-08-03 09:19:43,275] Trial 4 finished with value: 0.1502794512271881 and parameters: {'lr': 0.004930781002891095, 'weight_decay': 0.0004812349636925334}. Best is trial 1 with value: 0.14318454551696777.\n"]}],"source":["epochs = 5\n","\n","# Define the objective function for Optuna study\n","def objective(trial):\n","    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n","    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n","\n","    model = Autoencoder()\n","    model.to(device)\n","\n","    # Define optimizer and criterion (MSE loss function)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    criterion = nn.MSELoss()\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0.0\n","        for inputs, _ in train_loader:\n","            inputs = inputs.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, inputs)\n","            total_loss += loss.item() * inputs.size(0)\n","            loss.backward()\n","            optimizer.step()\n","\n","        avg_loss = total_loss / len(train_loader.dataset)\n","        val_loss = validation_loss(model, test_loader, criterion, device)\n","        trial.report(val_loss, step=epoch)\n","\n","        # Prune bad trials\n","        if trial.should_prune():\n","            raise optuna.TrialPruned()\n","\n","    return val_loss\n","\n","# Perform hyperparameter tuning with Optuna\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=5)\n","\n","# Get the best hyperparameters\n","best_params = study.best_params\n","best_lr = best_params['lr']\n","best_weight_decay = best_params['weight_decay']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67845,"status":"ok","timestamp":1691054456638,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"WSizWkNWIL74","outputId":"8fd6ea94-415f-40b2-fcc0-b19ce6ec8a02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5: Training Loss using Best Hyperparameters: 0.1686\n","Epoch 2/5: Training Loss using Best Hyperparameters: 0.1497\n","Epoch 3/5: Training Loss using Best Hyperparameters: 0.1482\n","Epoch 4/5: Training Loss using Best Hyperparameters: 0.1474\n","Epoch 5/5: Training Loss using Best Hyperparameters: 0.1468\n"]}],"source":["# Train the autoencoder model with the best hyperparameters\n","model = Autoencoder()\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n","criterion = nn.MSELoss()\n","\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0.0\n","    for inputs, _ in train_loader:\n","        inputs = inputs.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, inputs)\n","        total_loss += loss.item() * inputs.size(0)\n","        loss.backward()\n","        optimizer.step()\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    print(f\"Epoch {epoch + 1}/{epochs}: Training Loss using Best Hyperparameters: {avg_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2522,"status":"ok","timestamp":1691054459149,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"MBMxeJQkM9Xh","outputId":"7043d555-6d0f-4690-de3b-34b6931cfd33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.1437\n"]}],"source":["# Produce the test loss\n","model.eval()\n","test_loss = 0.0\n","with torch.no_grad():\n","    for inputs, _ in test_loader:\n","        inputs = inputs.to(device)\n","        outputs = model(inputs)\n","        loss = criterion(outputs, inputs)\n","        test_loss += loss.item() * inputs.size(0)\n","\n","test_loss /= len(test_loader.dataset)\n","print(f\"Test Loss: {test_loss:.4f}\")"]},{"cell_type":"markdown","source":["# PS1.C (20 points)\n","\n","Add zero-mean Gaussian noise with variance that ranges from 0 to 1 to the images and repeat the training exercise comparing results with PS1.B and explaining why adding noise is a good idea."],"metadata":{"id":"Mkj8ymOvrsWn"}},{"cell_type":"markdown","source":["Explain here"],"metadata":{"id":"mh1SsYIWrsPG"}},{"cell_type":"code","source":["# add the noise and repeat"],"metadata":{"id":"XWk_l5MUrwYF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This final section examines the results of training with zero-mean Gaussian noise added to the input images. The goal is to assess and compare the model's performance with added noise to that of the model's performance without noise added (from the previous section).\n","\n","**Adding Gaussian Noise**\n","\n","For the purpose of adding Gaussian noise to the input images, the function `add_noise` is defined, taking in two arguments: the input images `inputs` and a Gaussian noise level `noise_factor`, with a set standard deviation and zero mean - all while making sure that pixel values remain within the range [0, 1]\n","\n","**Repeating the Process**\n","\n","The process from the previous section is repeated, that is, training autoencoder CNN model with the noisy inputs and using Optuna for hyperparameter tuning. The losses, of course, will be recorded.\n","\n","**Comparson of Test Losses**\n","\n","The test loss (MSE) when adding the Gaussian noise is: 0.323. The test loss, 0.323, obtained when adding the noise is smaller than the test loss, 0.1437, obtained when the noise was not added. Adding noise to allows for the decoder to be more robust and reduce overfitting - the model essentially encouraged to learn and focus on the important features of the input images - eventually leading to improved reconstructions of the images."],"metadata":{"id":"viverlHvfW3Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJ5R8UMKkDqC"},"outputs":[],"source":["# Function to add Gaussian noise to the inputs\n","def add_noise(inputs, noise_factor=0.3):\n","    noisy = inputs + torch.randn_like(inputs) * noise_factor\n","    noisy = torch.clip(noisy, 0., 1.)\n","    return noisy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434924,"status":"ok","timestamp":1691054981869,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"MyfNZIELhgJc","outputId":"df7a6d8a-8721-4156-dc24-1f2330201658"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2023-08-03 09:22:20,575] A new study created in memory with name: no-name-fb819400-47d6-4050-b968-22bede10e730\n","[I 2023-08-03 09:23:49,815] Trial 0 finished with value: 0.15506750931739807 and parameters: {'lr': 2.527315894917555e-05, 'weight_decay': 0.00011884404253595709}. Best is trial 0 with value: 0.15506750931739807.\n","[I 2023-08-03 09:25:16,334] Trial 1 finished with value: 0.14672551219463348 and parameters: {'lr': 0.0002107086947761691, 'weight_decay': 5.124743572408872e-05}. Best is trial 1 with value: 0.14672551219463348.\n","[I 2023-08-03 09:26:43,182] Trial 2 finished with value: 0.15658902175426484 and parameters: {'lr': 3.8889170964738805e-05, 'weight_decay': 0.00042355218511782087}. Best is trial 1 with value: 0.14672551219463348.\n","[I 2023-08-03 09:28:10,159] Trial 3 finished with value: 0.15462566313743592 and parameters: {'lr': 0.00241960635034059, 'weight_decay': 0.00033288611852949255}. Best is trial 1 with value: 0.14672551219463348.\n","[I 2023-08-03 09:29:35,809] Trial 4 finished with value: 0.1558040891647339 and parameters: {'lr': 4.079387503306812e-05, 'weight_decay': 0.00033384578470776143}. Best is trial 1 with value: 0.14672551219463348.\n"]}],"source":["# Define the objective function for Optuna study\n","def objective(trial):\n","    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n","    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n","\n","    model_noisy = Autoencoder()\n","    model_noisy.to(device)\n","\n","    # Define optimizer and criterion (MSE loss function)\n","    optimizer = optim.Adam(model_noisy.parameters(), lr=lr, weight_decay=weight_decay)\n","    criterion = nn.MSELoss()\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model_noisy.train()\n","        total_loss = 0.0\n","        for inputs, _ in train_loader:\n","            noisy_inputs = add_noise(inputs, noise_factor=0.3)\n","            noisy_inputs = noisy_inputs.to(device)\n","            optimizer.zero_grad()\n","            outputs = model_noisy(noisy_inputs)\n","            loss = criterion(outputs, noisy_inputs)\n","            total_loss += loss.item() * noisy_inputs.size(0)\n","            loss.backward()\n","            optimizer.step()\n","\n","        avg_loss = total_loss / len(train_loader.dataset)\n","        val_loss = validation_loss(model_noisy, test_loader, criterion, device)\n","        trial.report(val_loss, step=epoch)\n","\n","        # Prune bad trials\n","        if trial.should_prune():\n","            raise optuna.TrialPruned()\n","\n","    return val_loss\n","\n","# Perform hyperparameter tuning with Optuna\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","study_noise = optuna.create_study(direction='minimize')\n","study_noise.optimize(objective, n_trials=5)\n","\n","# Get the best hyperparameters\n","best_params_noise = study_noise.best_params\n","best_lr_noise = best_params_noise['lr']\n","best_weight_decay_noise = best_params_noise['weight_decay']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14691,"status":"ok","timestamp":1691054997921,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"99UDNnM9hgHC","outputId":"dbee3724-afe8-4e8a-d3c0-a8f93ed0775f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5: Training Loss using Best Hyperparameters: 0.0149\n","Epoch 2/5: Training Loss using Best Hyperparameters: 0.0078\n","Epoch 3/5: Training Loss using Best Hyperparameters: 0.0071\n","Epoch 4/5: Training Loss using Best Hyperparameters: 0.0067\n","Epoch 5/5: Training Loss using Best Hyperparameters: 0.0065\n"]}],"source":["# Train the autoencoder model with the best hyperparameters\n","model_noisy = Autoencoder()\n","model_noisy.to(device)\n","optimizer = optim.Adam(model_noisy.parameters(), lr=best_lr_noise, weight_decay=best_weight_decay_noise)\n","criterion = nn.MSELoss()\n","\n","for epoch in range(epochs):\n","    model_noisy.train()\n","    total_loss = 0.0\n","    for inputs, _ in test_loader:\n","        noisy_inputs = add_noise(inputs, noise_factor=0.3)\n","        noisy_inputs = noisy_inputs.to(device)\n","        optimizer.zero_grad()\n","        outputs = model_noisy(noisy_inputs)\n","        loss = criterion(outputs, noisy_inputs)\n","        total_loss += loss.item() * noisy_inputs.size(0)\n","        loss.backward()\n","        optimizer.step()\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    print(f\"Epoch {epoch + 1}/{epochs}: Training Loss using Best Hyperparameters: {avg_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3781,"status":"ok","timestamp":1691055007561,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"uahEa63HhgEm","outputId":"3d8e2eb6-ee6e-4ba0-ac3c-b3dda137a878"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0323\n"]}],"source":["# Produce the test loss\n","model_noisy.eval()\n","test_loss_noise = 0.0\n","with torch.no_grad():\n","    for inputs, _ in test_loader:\n","        noisy_inputs = add_noise(inputs, noise_factor=0.3)\n","        noisy_inputs = noisy_inputs.to(device)\n","        outputs = model_noisy(noisy_inputs)\n","        loss = criterion(outputs, noisy_inputs)\n","        test_loss_noise += loss.item() * noisy_inputs.size(0)\n","\n","test_loss_noise /= len(test_loader.dataset)\n","print(f\"Test Loss: {test_loss_noise:.4f}\")"]},{"cell_type":"markdown","source":["Comparison of Test Loss Before Adding Noise and Test Loss After Adding Noise"],"metadata":{"id":"3JFJkP26sJdH"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1691055007561,"user":{"displayName":"C Vega","userId":"16458062472798774276"},"user_tz":240},"id":"n7zekqhMgUHC","outputId":"989b58bb-5acd-4794-897f-573ca8a1ceb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+----------------------+\n","| Test Loss | Test Loss with Noise |\n","+-----------+----------------------+\n","|   0.1437  |        0.0323        |\n","+-----------+----------------------+\n"]}],"source":["from prettytable import PrettyTable\n","\n","# Compare the test losses\n","table = PrettyTable()\n","table.field_names = [\"Test Loss\", \"Test Loss with Noise\"]\n","table.add_row([f\"{test_loss:.4f}\", f\"{test_loss_noise:.4f}\"])\n","\n","print(table)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1SYuS_m_q06DJcHcJdWBruSbJu505Wz7S","timestamp":1691055192133},{"file_id":"15vb6ajwMLW2gbidjw_4wn0IB7NnHu-Jg","timestamp":1691053715732}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}